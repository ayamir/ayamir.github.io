<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <script type="application/javascript" src='https://ayamir.github.io/js/theme-mode.js'></script>
    <link rel="stylesheet" href='https://ayamir.github.io/css/frameworks.min.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/github.min.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/github-style.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/light.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/dark.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/syntax.css' />
    <title>Note for Content Motion Viewport Prediction - Ayamir&#39;s blog</title>
    
    <link rel="icon" type="image/x-icon" href='/images/favicon.png'>
    
    <meta name="theme-color" content="#1e2327">

    
    <meta name="description"
  content="论文概况 Link：Viewport Prediction for Live 360-Degree Mobile Video Streaming Using User-Content Hybrid Motion Tracking
Level：Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2019
Keywords：Viewport prediction, content-based motion tracking, dynamic user interest model
" />
<meta name="keywords"
  content='Content motion, Viewport prediction, Live video' />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://ayamir.github.io/posts/papers/note-for-content-motion-viewport-prediction/" />


<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Note for Content Motion Viewport Prediction - Ayamir&#39;s blog" />
<meta name="twitter:description"
  content="论文概况 Link：Viewport Prediction for Live 360-Degree Mobile Video Streaming Using User-Content Hybrid Motion Tracking
Level：Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2019
Keywords：Viewport prediction, content-based motion tracking, dynamic user interest model
" />
<meta name="twitter:site" content="https://ayamir.github.io/" />
<meta name="twitter:creator" content="" />
<meta name="twitter:image"
  content="https://ayamir.github.io/">


<meta property="og:type" content="article" />
<meta property="og:title" content="Note for Content Motion Viewport Prediction - Ayamir&#39;s blog">
<meta property="og:description"
  content="论文概况 Link：Viewport Prediction for Live 360-Degree Mobile Video Streaming Using User-Content Hybrid Motion Tracking
Level：Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2019
Keywords：Viewport prediction, content-based motion tracking, dynamic user interest model
" />
<meta property="og:url" content="https://ayamir.github.io/posts/papers/note-for-content-motion-viewport-prediction/" />
<meta property="og:site_name" content="Note for Content Motion Viewport Prediction" />
<meta property="og:image"
  content="https://ayamir.github.io/">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">

<meta property="article:published_time" content="2021-12-20 10:47:18 &#43;0800 CST" />











</head>

<body>
  <div style="position: relative">
  <header class="Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap open Details--on">
    <div class="Header-item mobile-none" style="margin-top: -4px; margin-bottom: -4px;">
      <a class="Header-link" href="https://ayamir.github.io/">
        <img class="octicon" height="32" width="32" src="/images/GitHub-Mark-Light-32px.png">
      </a>
    </div>
    <div class="Header-item d-md-none">
      <button class="Header-link btn-link js-details-target" type="button"
        onclick="document.querySelector('#header-search').style.display = document.querySelector('#header-search').style.display == 'none'? 'block': 'none'">
        <img height="24" class="octicon octicon-three-bars" width="24" src="/images/GitHub-Mark-Light-32px.png">
      </button>
    </div>
    <div style="display: none;" id="header-search"
      class="Header-item Header-item--full flex-column flex-md-row width-full flex-order-2 flex-md-order-none mr-0 mr-md-3 mt-3 mt-md-0 Details-content--hidden-not-important d-md-flex">
      <div
        class="Header-search header-search flex-auto js-site-search position-relative flex-self-stretch flex-md-self-auto mb-3 mb-md-0 mr-0 mr-md-3 scoped-search site-scoped-search js-jump-to">
        <div class="position-relative">
          <form target="_blank" action="https://www.google.com/search" accept-charset="UTF-8" method="get"
            autocomplete="off">
            <label
              class="Header-search-label form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center">
              <input type="text"
                class="Header-search-input form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable"
                name="q" value="" placeholder="Search" autocomplete="off">
              <input type="hidden" name="q" value="site:https://ayamir.github.io/">
            </label>
          </form>
        </div>
      </div>
    </div>

    <div class="Header-item Header-item--full flex-justify-center d-md-none position-relative">
      <a class="Header-link " href="https://ayamir.github.io/">
        <img class="octicon octicon-mark-github v-align-middle" height="32" width="32" src="/images/GitHub-Mark-Light-32px.png">
      </a>
    </div>
    <div class="Header-item" style="margin-right: 0;">
      <a href="javascript:void(0)" class="Header-link no-select" onclick="switchTheme()">
        <svg style="fill: var(--color-profile-color-modes-toggle-moon);" class="no-select" viewBox="0 0 16 16"
          version="1.1" width="16" height="16">
          <path fill-rule="evenodd" clip-rule="evenodd"
            d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z">
          </path>
        </svg>
      </a>
    </div>
  </header>
</div>

  
<div>
  <main>
    <div class="gisthead pagehead bg-gray-light pb-0 pt-3 mb-4">
      <div class="px-0">
        <div class="mb-3 d-flex px-3 px-md-3 px-lg-5">
          <div class="flex-auto min-width-0 width-fit mr-3">
            <div class="d-flex">
              <div class="d-none d-md-block">
                <a class="avatar mr-2 flex-shrink-0" href="https://ayamir.github.io/">
                  <img class=" avatar-user"
                    src="/images/avatar.png"
                    width="32" height="32"></a>
              </div>
              <div class="d-flex flex-column">
                <h1 class="break-word f3 text-normal mb-md-0 mb-1">
                  <span class="author">
                    <a href="https://ayamir.github.io/"></a>
                  </span>
                  <span class="path-divider">/</span>
                  <strong class="css-truncate css-truncate-target mr-1" style="max-width: 410px">
                    <a href="https://ayamir.github.io/posts/papers/note-for-content-motion-viewport-prediction/">Note for Content Motion Viewport Prediction</a>
                  </strong>
                </h1>
                <div class="note m-0">
                  Created <relative-time datetime="Mon, 20 Dec 2021 10:47:18 &#43;0800"
                    class="no-wrap">
                    Mon, 20 Dec 2021 10:47:18 &#43;0800</relative-time>

                  
                  <span class="file-info-divider"></span>
                  Modified <relative-time datetime="Thu, 25 Apr 2024 22:29:35 &#43;0800"
                    class="no-wrap">
                    Thu, 25 Apr 2024 22:29:35 &#43;0800</relative-time>
                  
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-lg px-3 new-discussion-timeline">
      <div class="repository-content gist-content">
        <div>
          <div class="js-gist-file-update-container js-task-list-container file-box">
            <div id="file-pytest" class="file my-2">
              <div id="post-header" class="file-header d-flex flex-md-items-center flex-items-start sticky-header" style="z-index: 2">
                <div class="file-info d-flex flex-md-items-center flex-items-start flex-order-1 flex-auto">
                  <div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0">
                    
                    <summary id="toc-toggle" onclick="clickToc()" class="btn btn-octicon m-0 mr-2 p-2">
                      <svg aria-hidden="true" viewBox="0 0 16 16" height="16" width="16" class="octicon octicon-list-unordered">
                        <path fill-rule="evenodd" d="M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zM3 8a1 1 0 11-2 0 1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z"></path>
                      </svg>
                    </summary>
                    <details-menu class="SelectMenu" id="toc-details" style="display: none;">
                      <div class="SelectMenu-modal rounded-3 mt-1" style="max-height: 340px;">
                        <div class="SelectMenu-list SelectMenu-list--borderless p-2" style="overscroll-behavior: contain;" id="toc-list">
                        </div>
                      </div>
                    </details-menu>
                      3361 Words
                    

                  </div>
                  <div class="file-actions flex-order-2 pt-0">
                    
                    
                    <a class="muted-link mr-3" href="/tags/immersive-video">
                      <svg class="octicon octicon-tag" viewBox="0 0 16 16" version="1.1" width="16" height="16">
                        <path fill-rule="evenodd"
                          d="M2.5 7.775V2.75a.25.25 0 01.25-.25h5.025a.25.25 0 01.177.073l6.25 6.25a.25.25 0 010 .354l-5.025 5.025a.25.25 0 01-.354 0l-6.25-6.25a.25.25 0 01-.073-.177zm-1.5 0V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 010 2.474l-5.026 5.026a1.75 1.75 0 01-2.474 0l-6.25-6.25A1.75 1.75 0 011 7.775zM6 5a1 1 0 100 2 1 1 0 000-2z">
                        </path>
                      </svg>
                      Immersive Video
                    </a>
                    
                    
                  </div>
                </div>
              </div>


              <div class="Box-body px-5 pb-5" style="z-index: 1">
                <article class="markdown-body entry-content container-lg"><h2 id="论文概况">论文概况</h2>
<p>Link：<a href="https://dl.acm.org/doi/abs/10.1145/3328914">Viewport Prediction for Live 360-Degree Mobile Video Streaming Using User-Content Hybrid Motion Tracking</a></p>
<p>Level：Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2019</p>
<p>Keywords：Viewport prediction, content-based motion tracking, dynamic user interest model</p>
<h2 id="workflow">Workflow</h2>
<ul>
<li>Tracking：VR motion 追踪算法：应用了高斯混合模型来检测物体的运动。</li>
<li>Recovery：基于反馈的错误恢复算法：在运行时考虑实际的用户 viewport 来自动更正潜在的预测错误。</li>
<li>Update：viewport 动态更新算法：动态调整预测的 viewport 大小去覆盖感兴趣的潜在 viewport，同时尽可能保证最低的带宽消耗。</li>
<li>Evaluation：经验用户/视频评估：构建 VR viewport 预测方法原型，使用经验 360°视频和代表性的头部移动数据集评估。</li>
</ul>
<h2 id="全景直播推流的预备知识">全景直播推流的预备知识</h2>
<h3 id="vr-推流直播">VR 推流直播</h3>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211220152453073.png" alt="image-20211220152453073"></p>
<p>相比于传统的 2D 视频推流的特别之处：</p>
<ul>
<li>VR 系统是交互式的，viewport 的选择权在客户端；</li>
<li>呈现给用户的最终视图是整个视频的一部分；</li>
</ul>
<h3 id="用户头部移动的模式">用户头部移动的模式</h3>
<p>在大量的 360°视频观看过程中，用户主要的头部移动模式有 4 种，使用$i-j\ move$来表示；</p>
<p>其中$i$表示处于运动中的物体数量；$j$表示所有运动物体的运动方向的平均数。</p>
<ul>
<li>$1-1\ move$：单个物体以单一方向移动；</li>
<li>$1-n\ move$：单个物体以多个方向移动；</li>
<li>$m-n\ move$：多个物体以多个方向移动；</li>
<li>$Arbitrary\ move$：用户不跟随任何感兴趣的物体而移动，viewport 切换随机；</li>
</ul>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211220154440374.png" alt="image-20211220154440374"></p>
<p>现有的直播 VR 推流中的 viewport 预测方法是基于速度的方式，这种方式只对$1-1\ move$这一种模式有效。</p>
<p>本方案的目标是提出对 4 种模式都有效的预测策略。</p>
<h2 id="系统架构">系统架构</h2>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211220155438697.png" alt="image-20211220155438697"></p>
<h3 id="理论创新">理论创新</h3>
<ul>
<li>
<p>核心功能模块：</p>
<ol>
<li>
<p>motion detection：区分运动物体与静止的背景。</p>
</li>
<li>
<p>feature selection：选择代表性的特征并对运动物体做追踪。</p>
<p>这两个模块使系统能识别用户可能感兴趣的 viewport。</p>
</li>
</ol>
</li>
<li>
<p>使用贝叶斯方法分析用户观看行为并形式化用户的兴趣模型。</p>
<ol>
<li>
<p>使用错误恢复机制来使当预测错误被检测到时的预测 viewport 去适应实际的 viewport，尽管不能消除预测错误但是能避免在此基础上进一步的预测错误。</p>
</li>
<li>
<p>使用动态 viewport 更新算法来产生大小可变的 viewport，通过同时考虑跟踪到的 viewport 轨迹和用户当前的速度（矢量）。</p>
<p>这样，即使用户的运动模式很复杂也能有更高的概率去覆盖潜在的视图。</p>
</li>
</ol>
</li>
</ul>
<h3 id="具体实施">具体实施</h3>
<ul>
<li>
<p>虽然提出的运动追踪和错误处理机制是计算密集型的任务，但是这些组件都部署在 video packager 中，运行在服务端。</p>
</li>
<li>
<p>将生成 VR 视图的工作负载移动到服务端，进一步减少了客户端的计算开销以及网络开销。</p>
</li>
</ul>
<h2 id="形式化">形式化</h2>
<h3 id="基于运动轨迹的-viewport-预测">基于运动轨迹的 viewport 预测</h3>
<p>使用<a href="https://ieeexplore.ieee.org/document/1333992">GMM</a>完成运动检测，使用<a href="https://ieeexplore.ieee.org/document/323794">Shi-Tomasi algorithm</a>解决运动轨迹跟踪问题。</p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211220165231195.png" alt="image-20211220165231195"></p>
<ol>
<li>
<p>运动检测</p>
<p>GMM 前景提取</p>
</li>
<li>
<p>特征选取与过滤</p>
<p>采用 Shi-Tomasi algorithm 从视频中检测代表性的特征，直接检测得到的代表性特征数量较多而难以追踪。</p>
<p>采用两种过滤的方法来减少要追踪的特征数量。</p>
<ul>
<li>
<p>比较当前帧和前一帧的特征，只保留其共有的部分。</p>
</li>
<li>
<p>采用第 1 步中运动检测的方式，只保留运动的部分。</p>
</li>
</ul>
</li>
<li>
<p>viewport 生成</p>
<p>经过选择和过滤之后的特征通常分布在不能被单一用户视图所覆盖的广阔区域中。</p>
<p>在整个 360°视频中可能存在多个运动的物体，即$m-n\ move$。</p>
<p>提出一种系统的方式来产生用户最可能跟随观看的 viewport。</p>
<p>直觉是用户更可能将大部分注意力放在两种类型的物体上：</p>
<ul>
<li>离用户更近的物体。</li>
<li>就物理形状而言更“重要”的物体。</li>
</ul>
<p>这两种类型的物体大多包含最密集和最大量的特征，因此通过所有特征的重心来计算预测用户视图的中心。</p>
<p>对于剩余的特征列表：$\vec{F} = [f_1, f_2, f_3, &hellip;, f_k]$，其中$f_i(i = 1 &hellip; k)$表示特征$f_i = &lt;f^{(x)}_i, f^{(y)}_i&gt;$的像素点坐标，则预测出的 viewport 中心坐标可以计算出来：</p>
<p>$$
l_x = \frac{1}{k} \sum^k_{i=1} f^{(x)}_i;\ l_y = \frac{1}{k} \sum^k_{i=1} f^{(y)}_i.
$$</p>
<p>考虑到即使预测的 viewport 中包含用户观看的物体，预测得到的 viewport 也可能会与实际的 viewport 存在差异。</p>
<p>所以预测的 viewport 可能比实际的 viewport 要大，所以使用缩放因子$S_c$来产生预测的 viewport。</p>
<p>给出用户 viewport 的大小$S_{user}$，预测的 viewport 可以通过$S_{pre} = S_c \cdot S_{user}$计算出来。</p>
</li>
</ol>
<h3 id="基于用户反馈的错误恢复">基于用户反馈的错误恢复</h3>
<p>video packager 可以通过 HMD 和 web 服务器通过反向路径从用户处检索用户实际视图的反馈信息。</p>
<p>基于反馈的错误恢复机制在以下两种场景中表现良好：</p>
<ol>
<li>
<p>没有运动的物体</p>
<p>如果没有检测到运动的物体，则用户很可能是在观看静止的物体，这会导致基于运动目标的 viewport 预测失败。</p>
<p>在这种场景中，可以认为视频内容已经不再是决定用户 viewport 的因素，而只取决于用户自身的行为。</p>
<p>因此采用基于速度的方式来预测 viewport。（这样的决策可以在运动检测模块没有检测到运动物体时就做出）</p>
<p>一旦从反馈路径上得到用户信息，可以产生用户 viewport 位置向量：$\vec{L} = [l_1, l_2, l_3, &hellip;, l_M]$，其中$l_i$表示第$i$个帧中用户 viewport 的位置，$M$表示视频播放缓冲区中的帧数。那么可以计算 viewport 速度：</p>
<p>$$
\vec{V} = \frac{\vec{(l_2 - l_1)} + \vec{(l_3 - l_2)} &hellip;.(l_M - l_{M-1})}{M-1} = \frac{(\vec{l_M - l_1})}{M-1}
$$</p>
<pre><code>下一帧的预测位置$L_{M=1}$也可以计算出来：
</code></pre>
<p>$$
l_{M+1} = l_M + \vec{V}
$$</p>
</li>
<li>
<p>预测视图与实际视图的不匹配</p>
<p>一旦运动追踪策略检测到用户实际的视图和预测的视图不同，就会触发恢复机制去追踪用户实际在看着的物体。</p>
<p>可以使用运动追踪方式确定用户实际观察的物体的速度。</p>
<p>给出前一帧匹配的特征$\vec{FA} = [fA_1, fA_2, fA_3, &hellip;, fA_p]$和当前帧的特征$\vec{FB} = [fB_1, fB_2, fB_3, &hellip;, fB_p]$，可以计算出速度：</p>
<p>$$
V_x = \frac{1}{p} (\sum^p_{i=1} fB^{(x)}_i - \sum^p_{i=1}fA^{(x)}_i),<br>
V_y = \frac{1}{p} (\sum^p_{i=1} fB^{(y)}_i - \sum^p_{i=1}fA^{(y)}_i),
$$</p>
<p>假设预测的 viewpoint 是$(l_x, l_y)$，修改之后的 viewpoint 是$(l_x + V_x,\ l_y + V_y)$。</p>
</li>
</ol>
<h3 id="动态-viewport-更新">动态 viewport 更新</h3>
<p>前述的错误恢复机制发生在 viewport 预测错误出现之后，任务是避免未来更多的错误。</p>
<p>动态的 viewport 更新则努力避免 viewport 预测错误。</p>
<p>关键思想是扩大预测的 viewport 大小，以高概率去覆盖$m-n\ move$和$arbitrary\ move$下所有潜在的运动目标；更重要的是动态调整视图的大小去获得更高效的带宽利用率。</p>
<ul>
<li>
<p>对于一个 360°全景视频，将 360°的帧均分为$N = n \times n$个网格，每个网格看作是一个 tile，预测的 viewport 即为$N$个 tile 的子集。</p>
</li>
<li>
<p>使用贝叶斯方法分析用户的观看行为，每个 tile 分配一个独立的贝叶斯模型，所以每个 tile 可以独立更新。</p>
</li>
<li>
<p>设$X$表示用户 viewport，$Y$表示静态内容，$Z$表示运动物体。</p>
</li>
<li>
<p>未来的用户 viewport 可以以条件概率计算为$P(X|Y,\ Z)$，$Y$与$Z$相互独立。</p>
</li>
<li>
<p>用户的 viewport 可以通过反馈信息得出$P(X)$；用户观看静态特征可以表示为$P(X|Y)$；用户观看动态特征可以表示为$P(X|Z)$。</p>
</li>
<li>
<p>$P(X|Y, Z)$可以计算为：</p>
<p>$$
P(X|Y, Z) = \frac{P(Y|X) \cdot P(Z|X) \cdot P(X)}{P(Y, Z)}
$$</p>
</li>
<li>
<p>只要用户开始观看，对于 tile $T_i$，就能得到其先验概率$P(Y_i|X_i)$和$P(Z_i|X_i)$，进而根据贝叶斯模型计算出$P(X|Y, Z)$。</p>
</li>
</ul>
<p>为每个 tile 定义两种属性：</p>
<ol>
<li>当前状态：表示此 tile 是否属于预测的 viewport（属于标记为$PREDICTED$，不属于标记为$NONPREDICTED$）。</li>
<li>生存期：表示此 tile 会在 view port 中存在多长时间（例如定义 3 种等级：$ZERO$，$MEDIUM$，$HIGH$，实际的定义划分可以根据具体的用户和视频设定）。</li>
</ol>
<h2 id="预测步骤">预测步骤</h2>
<p>按照形式化中提出的 3 步，分为系统初始化、帧级别的更新、缓冲区级别的更新。</p>
<ol>
<li>
<p>系统初始化</p>
<p>初始化阶段中，view 更新算法将所有的$N$个 tile 标注为$PREDICTED$，并将生存期设置为$MEDIUM$，即系统向用户发送完整的一帧作为自举。</p>
<p>这样设定的原因在于：当用户第一次启动视频会话时，允许“环视”类型的移动，这可能会覆盖 360°帧的任意 viewport。</p>
</li>
<li>
<p>帧级别的更新</p>
<p>给定一帧，应用修改后的 motion 追踪算法在运动区域中选择特征，而不使用特征的密度做进一步的过滤。</p>
<p>使用有多个 tile 的多个视图来覆盖一个放大的区域，该区域包含作为预测 viewport 的移动对象上的所有特征，这样就能适应$m-n\ move$中的用户行为。</p>
<p>设计帧级别的算法标记选择的 tile 作为$PREDICTED$并设置其生存期为$HIGH$（直觉上讲运动中的物体或用户所感兴趣的静态特征会更以长时间保留在 viewport 之中）。</p>
</li>
<li>
<p>缓冲区级别的更新</p>
<p>以缓冲区长度为间隔检索用户的实际视图，基于此可以对 tile 的两种属性做出调整。</p>
<ol>
<li>对于与用户实际视图重叠的 tile，设置为$PREDICTED$和$HIGH$。</li>
<li>对于用户实际视图没有出现但出现在预测的视图中的 tile，生存期减 1，如果生存期减为$ZERO$，就重设其状态为$NONPREDICTED$，将其从预测的 viewport 中移除。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211220221933915.png" alt="image-20211220221933915"></p>
</li>
</ol></article>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </main>
</div>
<script type="application/javascript" src='https://ayamir.github.io/js/toc.js'></script>
<link rel="stylesheet" href='https://ayamir.github.io/css/toc.css' />


<div id="gitalk-container" class="gitalk-container"></div>
<link rel="stylesheet" href='https://ayamir.github.io/css/gitalk.css'>
<script src='https://ayamir.github.io/js/gitalk.min.js'></script>
<script>
  const gitalk = new Gitalk({
    clientID: '1ee3454a8f1f370a7934',
    clientSecret: '737cbeaf81ce60b50fafd2b0d6c7ebfa42826555',
    repo: 'repo',
    owner: 'ayamir',
    admin: ['ayamir'],
    id: eval("location.pathname"), 
    distractionFreeMode: false 
  });
  (function() {
    gitalk.render('gitalk-container');
  })();
</script>


  <div class="footer container-xl width-full p-responsive">
  <div
    class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between flex-sm-items-center pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light ">
    <a aria-label="Homepage" title="GitHub" class="footer-octicon d-none d-lg-block mr-lg-4" href="https://ayamir.github.io/">
      <svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="24">
        <path fill-rule="evenodd"
          d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z">
        </path>
      </svg>
    </a>
    <ul class="list-style-none d-flex flex-wrap col-12 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0">
      
      <li class="mr-3 mr-lg-0">Theme by <a href='https://github.com/MeiK2333/github-style'>github-style</a></li>
      
    </ul>
  </div>
  <div class="d-flex flex-justify-center pb-6">
    <span class="f6 text-gray-light"></span>
  </div>


</div>
</body>

<script type="application/javascript" src="https://ayamir.github.io/js/github-style.js"></script>

<link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>




</html>