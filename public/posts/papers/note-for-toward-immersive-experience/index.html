<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <script type="application/javascript" src='https://ayamir.github.io/js/theme-mode.js'></script>
    <link rel="stylesheet" href='https://ayamir.github.io/css/frameworks.min.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/github.min.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/github-style.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/light.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/dark.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/syntax.css' />
    <title>Note for Toward Immersive Experience - Ayamir&#39;s blog</title>
    
    <link rel="icon" type="image/x-icon" href='/images/favicon.png'>
    
    <meta name="theme-color" content="#1e2327">

    
    <meta name="description"
  content="Overview Link: Toward Immersive Experience: Evaluation for Interactive Network Services
Level: IEEE Network 2022
Keywords: QoE Metrics
" />
<meta name="keywords"
  content='QoE Metrics' />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://ayamir.github.io/posts/papers/note-for-toward-immersive-experience/" />


<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Note for Toward Immersive Experience - Ayamir&#39;s blog" />
<meta name="twitter:description"
  content="Overview Link: Toward Immersive Experience: Evaluation for Interactive Network Services
Level: IEEE Network 2022
Keywords: QoE Metrics
" />
<meta name="twitter:site" content="https://ayamir.github.io/" />
<meta name="twitter:creator" content="" />
<meta name="twitter:image"
  content="https://ayamir.github.io/">


<meta property="og:type" content="article" />
<meta property="og:title" content="Note for Toward Immersive Experience - Ayamir&#39;s blog">
<meta property="og:description"
  content="Overview Link: Toward Immersive Experience: Evaluation for Interactive Network Services
Level: IEEE Network 2022
Keywords: QoE Metrics
" />
<meta property="og:url" content="https://ayamir.github.io/posts/papers/note-for-toward-immersive-experience/" />
<meta property="og:site_name" content="Note for Toward Immersive Experience" />
<meta property="og:image"
  content="https://ayamir.github.io/">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">

<meta property="article:published_time" content="2022-03-09 11:20:37 &#43;0800 CST" />











<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123456-789', 'auto');
	
	ga('send', 'pageview');
}
</script>


</head>

<body>
  <div style="position: relative">
  <header class="Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap open Details--on">
    <div class="Header-item mobile-none" style="margin-top: -4px; margin-bottom: -4px;">
      <a class="Header-link" href="https://ayamir.github.io/">
        <img class="octicon" height="32" width="32" src="/images/GitHub-Mark-Light-32px.png">
      </a>
    </div>
    <div class="Header-item d-md-none">
      <button class="Header-link btn-link js-details-target" type="button"
        onclick="document.querySelector('#header-search').style.display = document.querySelector('#header-search').style.display == 'none'? 'block': 'none'">
        <img height="24" class="octicon octicon-three-bars" width="24" src="/images/GitHub-Mark-Light-32px.png">
      </button>
    </div>
    <div style="display: none;" id="header-search"
      class="Header-item Header-item--full flex-column flex-md-row width-full flex-order-2 flex-md-order-none mr-0 mr-md-3 mt-3 mt-md-0 Details-content--hidden-not-important d-md-flex">
      <div
        class="Header-search header-search flex-auto js-site-search position-relative flex-self-stretch flex-md-self-auto mb-3 mb-md-0 mr-0 mr-md-3 scoped-search site-scoped-search js-jump-to">
        <div class="position-relative">
          <form target="_blank" action="https://www.google.com/search" accept-charset="UTF-8" method="get"
            autocomplete="off">
            <label
              class="Header-search-label form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center">
              <input type="text"
                class="Header-search-input form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable"
                name="q" value="" placeholder="Search" autocomplete="off">
              <input type="hidden" name="q" value="site:https://ayamir.github.io/">
            </label>
          </form>
        </div>
      </div>
    </div>

    <div class="Header-item Header-item--full flex-justify-center d-md-none position-relative">
      <a class="Header-link " href="https://ayamir.github.io/">
        <img class="octicon octicon-mark-github v-align-middle" height="32" width="32" src="/images/GitHub-Mark-Light-32px.png">
      </a>
    </div>
    <div class="Header-item" style="margin-right: 0;">
      <a href="javascript:void(0)" class="Header-link no-select" onclick="switchTheme()">
        <svg style="fill: var(--color-profile-color-modes-toggle-moon);" class="no-select" viewBox="0 0 16 16"
          version="1.1" width="16" height="16">
          <path fill-rule="evenodd" clip-rule="evenodd"
            d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z">
          </path>
        </svg>
      </a>
    </div>
  </header>
</div>

  
<div>
  <main>
    <div class="gisthead pagehead bg-gray-light pb-0 pt-3 mb-4">
      <div class="px-0">
        <div class="mb-3 d-flex px-3 px-md-3 px-lg-5">
          <div class="flex-auto min-width-0 width-fit mr-3">
            <div class="d-flex">
              <div class="d-none d-md-block">
                <a class="avatar mr-2 flex-shrink-0" href="https://ayamir.github.io/">
                  <img class=" avatar-user"
                    src="/images/avatar.png"
                    width="32" height="32"></a>
              </div>
              <div class="d-flex flex-column">
                <h1 class="break-word f3 text-normal mb-md-0 mb-1">
                  <span class="author">
                    <a href="https://ayamir.github.io/"></a>
                  </span>
                  <span class="path-divider">/</span>
                  <strong class="css-truncate css-truncate-target mr-1" style="max-width: 410px">
                    <a href="https://ayamir.github.io/posts/papers/note-for-toward-immersive-experience/">Note for Toward Immersive Experience</a>
                  </strong>
                </h1>
                <div class="note m-0">
                  Created <relative-time datetime="Wed, 09 Mar 2022 11:20:37 &#43;0800"
                    class="no-wrap">
                    Wed, 09 Mar 2022 11:20:37 &#43;0800</relative-time>

                  
                  <span class="file-info-divider"></span>
                  Modified <relative-time datetime="Fri, 26 Apr 2024 09:02:15 &#43;0800"
                    class="no-wrap">
                    Fri, 26 Apr 2024 09:02:15 &#43;0800</relative-time>
                  
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-lg px-3 new-discussion-timeline">
      <div class="repository-content gist-content">
        <div>
          <div class="js-gist-file-update-container js-task-list-container file-box">
            <div id="file-pytest" class="file my-2">
              <div id="post-header" class="file-header d-flex flex-md-items-center flex-items-start sticky-header" style="z-index: 2">
                <div class="file-info d-flex flex-md-items-center flex-items-start flex-order-1 flex-auto">
                  <div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0">
                    
                    <summary id="toc-toggle" onclick="clickToc()" class="btn btn-octicon m-0 mr-2 p-2">
                      <svg aria-hidden="true" viewBox="0 0 16 16" height="16" width="16" class="octicon octicon-list-unordered">
                        <path fill-rule="evenodd" d="M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zM3 8a1 1 0 11-2 0 1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z"></path>
                      </svg>
                    </summary>
                    <details-menu class="SelectMenu" id="toc-details" style="display: none;">
                      <div class="SelectMenu-modal rounded-3 mt-1" style="max-height: 340px;">
                        <div class="SelectMenu-list SelectMenu-list--borderless p-2" style="overscroll-behavior: contain;" id="toc-list">
                        </div>
                      </div>
                    </details-menu>
                      1102 Words
                    

                  </div>
                  <div class="file-actions flex-order-2 pt-0">
                    
                    
                    <a class="muted-link mr-3" href="/tags/immersive-video">
                      <svg class="octicon octicon-tag" viewBox="0 0 16 16" version="1.1" width="16" height="16">
                        <path fill-rule="evenodd"
                          d="M2.5 7.775V2.75a.25.25 0 01.25-.25h5.025a.25.25 0 01.177.073l6.25 6.25a.25.25 0 010 .354l-5.025 5.025a.25.25 0 01-.354 0l-6.25-6.25a.25.25 0 01-.073-.177zm-1.5 0V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 010 2.474l-5.026 5.026a1.75 1.75 0 01-2.474 0l-6.25-6.25A1.75 1.75 0 011 7.775zM6 5a1 1 0 100 2 1 1 0 000-2z">
                        </path>
                      </svg>
                      Immersive Video
                    </a>
                    
                    
                  </div>
                </div>
              </div>


              <div class="Box-body px-5 pb-5" style="z-index: 1">
                <article class="markdown-body entry-content container-lg"><h1 id="overview">Overview</h1>
<p>Link: <a href="https://ieeexplore.ieee.org/document/9679801">Toward Immersive Experience: Evaluation for Interactive Network Services</a></p>
<p>Level: IEEE Network 2022</p>
<p>Keywords: QoE Metrics</p>
<h1 id="background">Background</h1>
<p>Compared with traditional QoE for regular video/audio services, the existing work on IE is still in its infancy. This work aims at providing systematic and comprehensive research on IE for interactive network services, mainly studying the following three fundamental and challenging issues.</p>
<ul>
<li><em>What is the essential difference between IE and traditional QoE?</em></li>
<li><em>Which categories of factors mainly influence IE?</em></li>
<li><em>How to evaluate IE in an efficient and intelligent manner?</em></li>
</ul>
<h1 id="ie-versus-traditional-qoe">IE versus traditional QoE</h1>
<h2 id="theoretical-definitions">Theoretical definitions</h2>
<p>Existing concepts of IE can be classified into two categories.</p>
<ul>
<li>The subjective sense of being surrounded or experiencing multi-sensory stimulation when interacting with the virtual environment.</li>
<li>The user&rsquo;s psychological state of deep involvement, engagement, absorption, or engrossment.</li>
</ul>
<p>Traditional QoE:</p>
<ul>
<li>A subjective measure from the user perspective of the overall value of the provided service and application.</li>
</ul>
<p>We can summary two significant points as follows to distinguish IE and traditional QoE:</p>
<ul>
<li>Both IE and traditional QoE are devoted to characterizing user&rsquo;s subjective experience for network services.</li>
<li>In terms of application scenarios, IE concentrates on the evaluation of network services equipped with interactive characteristics while traditional QoE is generally appropriate for regular audio/video services.</li>
</ul>
<p>IE is much more complex, fine-grained and multi-dimensional perception, which is produced through the interplay between multi-sensory data and diverse cognitive processes.</p>
<h2 id="technical-challenges">Technical challenges</h2>
<ul>
<li>Growing data volume</li>
<li>Stricter delay constraint</li>
<li>Increasing data dimension</li>
</ul>
<h2 id="ifs-on-ie">IFs on IE</h2>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20220309164036088.png" alt="image-20220309164036088"></p>
<h2 id="network-aware-ifs">Network-aware IFs</h2>
<p>Actually, when heterogeneous streams are delivered to the network, their transmission quality is dependent on the outside network conditions(e.g., delay, jitter, throughput, and so on), as well as the streaming strategy (e.g., encoding, transmission protocol, and so on) inside streams, which ultimately impact end users&rsquo; IE. To this end, we can further subdivide this category into two classes including network QoS and stream-related IFs.</p>
<ul>
<li>
<p>QoS:</p>
<ul>
<li>low latency</li>
<li>high throughput</li>
<li>high reliability</li>
<li>temporal synchronization among heterogeneous streams</li>
</ul>
</li>
<li>
<p>stream-related IFs</p>
<ul>
<li>the form of data compression strategy</li>
<li>resource scheduling scheme</li>
</ul>
</li>
</ul>
<h2 id="user-aware-ifs">User-aware IFs</h2>
<p>IE may be influenced by human users while human users can perceive IE, for which we can subdivide this category into three classes based on such correlations.</p>
<ul>
<li>User profile</li>
<li>Physiological IFs</li>
<li>Psychological IFs</li>
</ul>
<p>It is obvious that users with diverse user profiles have distinctive influences on IE.</p>
<p>The psychology and physiology of users can highly reflect the IE for the application.</p>
<ul>
<li>For psychological IFs, they are able to directly demonstrate a user&rsquo;s positive or negative feedback for interactive network services. However, this can hardly be simply measured.</li>
<li>For physiological IFs, some of them(e.g., heart rate, blood pressure) can be objectively measured by affordable medical sensors.</li>
</ul>
<h2 id="device-aware-ifs">Device-aware IFs</h2>
<p>With regard to device-aware IFs, two broad classes can be gotten according to internal systems(e.g., CPU) and external specifications(e.g., screen size, FOV) of the device.</p>
<p>IE management in the device level mainly lies in two aspects.</p>
<ul>
<li>The selection of terminal type(e.g., mobile phone, laptop, VR/AR glasses)</li>
<li>The corresponding possession of hardware(e.g., CPU, GPU, battery).</li>
</ul>
<h2 id="context-aware-ifs">Context-aware IFs</h2>
<p>Typically, IE for interactive network services is generated by interacting with the virtual environment. To this end, we can derive two primary classes.</p>
<ul>
<li>Virtual context: focuses on the specific virtual application scenario.</li>
<li>Physical context: focuses on its surrounding physical environment.</li>
</ul>
<p>We can provide constructive suggestions for different contexts. For example, online virtual games are appropriate to play outside for the broad horizon, but watching a 3D film is more proper inside the home.</p>
<p>We can suggest appropriate application types with different technical requirement to guarantee users&rsquo; IE according to existing network resources and the surrounding environment.</p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20220309180717298.png" alt="image-20220309180717298"></p>
<h1 id="light-weight-ie-evaluation">Light-weight IE evaluation</h1>
<p>We proposed two light-weight IE evaluation approaches by respectively exploiting the AI technology and exploring the mathematical relationship among IFs and IE, which are appropriate for different cases according to the data amount.</p>
<h2 id="ai-based">AI-based</h2>
<p>Existing popular studies focusing on DL-based models(e.g., DNNs, LSTMs) can hardly satisfy the stringent delay requirement.</p>
<p>We employ a multi-view learning combining with lightweight ML methods(e.g., SVM, decision tree) for fast and accurate IE evaluation.</p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20220309180821654.png" alt="image-20220309180821654"></p>
<p>The raw data through multi-view learning is first represented by multiple feature extractors according to their heterogeneous properties. Each modality is regraded as a particular view for multi-modal applications. Motivations are:</p>
<ol>
<li>It can provide efficient dimension reduction via subspace mapping. Subspace learning-based approaches can map the high-dimensional raw data to a latent subspace, in which its dimensionality is lower than that of raw data.</li>
<li>Multi-view learning is more applicable to the IE context with abundant infomation, which can overcome the weakness of ML-based methods regarding evaluation accuracy for interactive network services.</li>
<li>Multi-view learning can take full advantage of the associated and complementary features from redundant views for evaluation performance improvement.</li>
</ol>
<h2 id="statistical-function-based">Statistical function-based</h2>
<p>AI-based approach may achieve better evaluation performances under large amounts of data, they lack strong interpretability and cannot explicitly explain the inherent relations among IFs and IE.</p>
<p>We introduced statistical function-based approach to analyze the mathematical relationship among IFs and IF under limited data.</p>
<p>Existing statistical function-based approaches for user experience evaluation are broadly divided into three categories:</p>
<ul>
<li>Exponential model</li>
<li>Logarithmic model</li>
<li>Linear regression model</li>
</ul>
<p>Notably, in order to further improve evaluation performance for interactive network services via statistical function-based approaches, two fundamental and significant issues need to be concerned as follows:</p>
<ol>
<li>How to comprehensively explore diverse and various IFs for accurate IE evaluation?</li>
<li>How to conduct an efficient dimension reduction method for fast IE evaluation?</li>
</ol>
<h1 id="case-study">Case study</h1>
<h2 id="multi-view-generation">Multi-view generation</h2>
<p>We can construct multiple views from expert prior knowledge or via the random subspace method, which is a random sampling algorithm for automatic feature set partitioning. Here we partition multi-modal data into three specific views according to different modalites.(e.g., audio, video, and haptic signals).</p>
<h2 id="view-combination">View combination</h2>
<p>Then we adopt subspace learning-based approaches to obtain an appropriate subspace from the above-mentioned multiple views. Importantly, canonical correlation analysis in subspace learning plays a significant role in dimension reduction, and outputs the optimal projection for each view.</p>
<h3 id="ie-evaluation">IE evaluation</h3>
<p>Finally, based on the optimal and combined projection subspace, decision tree is deployed here to evaluation IE.</p>
<p>The key point is find a general and robust evaluation approach:</p>
<p>$$
f: X \rarr Y
$$</p>
<p>Result is:</p>
<p>$$
Y = X^{\top} {\beta} + {\epsilon}
$$</p>
<p>${\epsilon}$ is the noise, ${\beta}$ can be considered as influencing degree of various IFs to the IE.</p>
<p>IE evaluation for multi-modal applications must satisfy more stringent delay requirements in the context of higher-dimensional data. So we apply the <a href="https://www.doi.org/10.1080/10618600.1998.10474784">LASSO estimation</a>, which is equipped with sparse solutions for the linear regression model, is incorporated to alleviate the issue of high-dimensional data for fast IE evaluation.</p>
<p>Dataset: <a href="http://8.133.175.194/">VisTouch</a></p>
<p>Compare obejcts:</p>
<ul>
<li>Ridge regression</li>
<li>Exponential model</li>
</ul>
<p>Performance metric: MAE</p>
<p>Test result:</p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20220309202425350.png" alt="image-20220309202425350"></p></article>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </main>
</div>
<script type="application/javascript" src='https://ayamir.github.io/js/toc.js'></script>
<link rel="stylesheet" href='https://ayamir.github.io/css/toc.css' />


<div id="gitalk-container" class="gitalk-container"></div>
<link rel="stylesheet" href='https://ayamir.github.io/css/gitalk.css'>
<script src='https://ayamir.github.io/js/gitalk.min.js'></script>
<script>
  const gitalk = new Gitalk({
    clientID: '1ee3454a8f1f370a7934',
    clientSecret: '737cbeaf81ce60b50fafd2b0d6c7ebfa42826555',
    repo: 'ayamir.github.io',
    owner: 'ayamir',
    admin: ['ayamir'],
    id: eval("location.pathname"), 
    distractionFreeMode: false 
  });
  (function() {
    gitalk.render('gitalk-container');
  })();
</script>


  <div class="footer container-xl width-full p-responsive">
  <div
    class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between flex-sm-items-center pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light ">
    <a aria-label="Homepage" title="GitHub" class="footer-octicon d-none d-lg-block mr-lg-4" href="https://ayamir.github.io/">
      <svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="24">
        <path fill-rule="evenodd"
          d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z">
        </path>
      </svg>
    </a>
    <ul class="list-style-none d-flex flex-wrap col-12 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0">
      
      <li class="mr-3 mr-lg-0">Theme by <a href='https://github.com/MeiK2333/github-style'>github-style</a></li>
      
    </ul>
  </div>
  <div class="d-flex flex-justify-center pb-6">
    <span class="f6 text-gray-light"></span>
  </div>


</div>
</body>

<script type="application/javascript" src="https://ayamir.github.io/js/github-style.js"></script>

<link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>




</html>