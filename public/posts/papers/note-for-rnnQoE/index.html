<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <script type="application/javascript" src='https://ayamir.github.io/js/theme-mode.js'></script>
    <link rel="stylesheet" href='https://ayamir.github.io/css/frameworks.min.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/github.min.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/github-style.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/light.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/dark.css' />
    <link rel="stylesheet" href='https://ayamir.github.io/css/syntax.css' />
    <title>Note for RnnQoE - Ayamir&#39;s blog</title>
    
    <link rel="icon" type="image/x-icon" href='/images/favicon.png'>
    
    <meta name="theme-color" content="#1e2327">

    
    <meta name="description"
  content="论文概况 Link：QoE-driven Mobile 360 Video Streaming: Predictive View Generation and Dynamic Tile Selection
Level：ICCC 2021
Keywords：QoE maximization，Trajectory-based viewport prediction，Dynamic tile selection，Differential weight on FOV tiles
" />
<meta name="keywords"
  content='Immersive Video' />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://ayamir.github.io/posts/papers/note-for-rnnQoE/" />


<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Note for RnnQoE - Ayamir&#39;s blog" />
<meta name="twitter:description"
  content="论文概况 Link：QoE-driven Mobile 360 Video Streaming: Predictive View Generation and Dynamic Tile Selection
Level：ICCC 2021
Keywords：QoE maximization，Trajectory-based viewport prediction，Dynamic tile selection，Differential weight on FOV tiles
" />
<meta name="twitter:site" content="https://ayamir.github.io/" />
<meta name="twitter:creator" content="" />
<meta name="twitter:image"
  content="https://ayamir.github.io/">


<meta property="og:type" content="article" />
<meta property="og:title" content="Note for RnnQoE - Ayamir&#39;s blog">
<meta property="og:description"
  content="论文概况 Link：QoE-driven Mobile 360 Video Streaming: Predictive View Generation and Dynamic Tile Selection
Level：ICCC 2021
Keywords：QoE maximization，Trajectory-based viewport prediction，Dynamic tile selection，Differential weight on FOV tiles
" />
<meta property="og:url" content="https://ayamir.github.io/posts/papers/note-for-rnnQoE/" />
<meta property="og:site_name" content="Note for RnnQoE" />
<meta property="og:image"
  content="https://ayamir.github.io/">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">

<meta property="article:published_time" content="2021-12-16 19:53:10 &#43;0800 CST" />











<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123456-789', 'auto');
	
	ga('send', 'pageview');
}
</script>


</head>

<body>
  <div style="position: relative">
  <header class="Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap open Details--on">
    <div class="Header-item mobile-none" style="margin-top: -4px; margin-bottom: -4px;">
      <a class="Header-link" href="https://ayamir.github.io/">
        <img class="octicon" height="32" width="32" src="/images/GitHub-Mark-Light-32px.png">
      </a>
    </div>
    <div class="Header-item d-md-none">
      <button class="Header-link btn-link js-details-target" type="button"
        onclick="document.querySelector('#header-search').style.display = document.querySelector('#header-search').style.display == 'none'? 'block': 'none'">
        <img height="24" class="octicon octicon-three-bars" width="24" src="/images/GitHub-Mark-Light-32px.png">
      </button>
    </div>
    <div style="display: none;" id="header-search"
      class="Header-item Header-item--full flex-column flex-md-row width-full flex-order-2 flex-md-order-none mr-0 mr-md-3 mt-3 mt-md-0 Details-content--hidden-not-important d-md-flex">
      <div
        class="Header-search header-search flex-auto js-site-search position-relative flex-self-stretch flex-md-self-auto mb-3 mb-md-0 mr-0 mr-md-3 scoped-search site-scoped-search js-jump-to">
        <div class="position-relative">
          <form target="_blank" action="https://www.google.com/search" accept-charset="UTF-8" method="get"
            autocomplete="off">
            <label
              class="Header-search-label form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center">
              <input type="text"
                class="Header-search-input form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable"
                name="q" value="" placeholder="Search" autocomplete="off">
              <input type="hidden" name="q" value="site:https://ayamir.github.io/">
            </label>
          </form>
        </div>
      </div>
    </div>

    <div class="Header-item Header-item--full flex-justify-center d-md-none position-relative">
      <a class="Header-link " href="https://ayamir.github.io/">
        <img class="octicon octicon-mark-github v-align-middle" height="32" width="32" src="/images/GitHub-Mark-Light-32px.png">
      </a>
    </div>
    <div class="Header-item" style="margin-right: 0;">
      <a href="javascript:void(0)" class="Header-link no-select" onclick="switchTheme()">
        <svg style="fill: var(--color-profile-color-modes-toggle-moon);" class="no-select" viewBox="0 0 16 16"
          version="1.1" width="16" height="16">
          <path fill-rule="evenodd" clip-rule="evenodd"
            d="M4.52208 7.71754C7.5782 7.71754 10.0557 5.24006 10.0557 2.18394C10.0557 1.93498 10.0392 1.68986 10.0074 1.44961C9.95801 1.07727 10.3495 0.771159 10.6474 0.99992C12.1153 2.12716 13.0615 3.89999 13.0615 5.89383C13.0615 9.29958 10.3006 12.0605 6.89485 12.0605C3.95334 12.0605 1.49286 10.001 0.876728 7.24527C0.794841 6.87902 1.23668 6.65289 1.55321 6.85451C2.41106 7.40095 3.4296 7.71754 4.52208 7.71754Z">
          </path>
        </svg>
      </a>
    </div>
  </header>
</div>

  
<div>
  <main>
    <div class="gisthead pagehead bg-gray-light pb-0 pt-3 mb-4">
      <div class="px-0">
        <div class="mb-3 d-flex px-3 px-md-3 px-lg-5">
          <div class="flex-auto min-width-0 width-fit mr-3">
            <div class="d-flex">
              <div class="d-none d-md-block">
                <a class="avatar mr-2 flex-shrink-0" href="https://ayamir.github.io/">
                  <img class=" avatar-user"
                    src="/images/avatar.png"
                    width="32" height="32"></a>
              </div>
              <div class="d-flex flex-column">
                <h1 class="break-word f3 text-normal mb-md-0 mb-1">
                  <span class="author">
                    <a href="https://ayamir.github.io/"></a>
                  </span>
                  <span class="path-divider">/</span>
                  <strong class="css-truncate css-truncate-target mr-1" style="max-width: 410px">
                    <a href="https://ayamir.github.io/posts/papers/note-for-rnnQoE/">Note for RnnQoE</a>
                  </strong>
                </h1>
                <div class="note m-0">
                  Created <relative-time datetime="Thu, 16 Dec 2021 19:53:10 &#43;0800"
                    class="no-wrap">
                    Thu, 16 Dec 2021 19:53:10 &#43;0800</relative-time>

                  
                  <span class="file-info-divider"></span>
                  Modified <relative-time datetime="Fri, 26 Apr 2024 09:02:15 &#43;0800"
                    class="no-wrap">
                    Fri, 26 Apr 2024 09:02:15 &#43;0800</relative-time>
                  
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-lg px-3 new-discussion-timeline">
      <div class="repository-content gist-content">
        <div>
          <div class="js-gist-file-update-container js-task-list-container file-box">
            <div id="file-pytest" class="file my-2">
              <div id="post-header" class="file-header d-flex flex-md-items-center flex-items-start sticky-header" style="z-index: 2">
                <div class="file-info d-flex flex-md-items-center flex-items-start flex-order-1 flex-auto">
                  <div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0">
                    
                    <summary id="toc-toggle" onclick="clickToc()" class="btn btn-octicon m-0 mr-2 p-2">
                      <svg aria-hidden="true" viewBox="0 0 16 16" height="16" width="16" class="octicon octicon-list-unordered">
                        <path fill-rule="evenodd" d="M2 4a1 1 0 100-2 1 1 0 000 2zm3.75-1.5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zm0 5a.75.75 0 000 1.5h8.5a.75.75 0 000-1.5h-8.5zM3 8a1 1 0 11-2 0 1 1 0 012 0zm-1 6a1 1 0 100-2 1 1 0 000 2z"></path>
                      </svg>
                    </summary>
                    <details-menu class="SelectMenu" id="toc-details" style="display: none;">
                      <div class="SelectMenu-modal rounded-3 mt-1" style="max-height: 340px;">
                        <div class="SelectMenu-list SelectMenu-list--borderless p-2" style="overscroll-behavior: contain;" id="toc-list">
                        </div>
                      </div>
                    </details-menu>
                      3276 Words
                    

                  </div>
                  <div class="file-actions flex-order-2 pt-0">
                    
                    
                    <a class="muted-link mr-3" href="/tags/immersive-video">
                      <svg class="octicon octicon-tag" viewBox="0 0 16 16" version="1.1" width="16" height="16">
                        <path fill-rule="evenodd"
                          d="M2.5 7.775V2.75a.25.25 0 01.25-.25h5.025a.25.25 0 01.177.073l6.25 6.25a.25.25 0 010 .354l-5.025 5.025a.25.25 0 01-.354 0l-6.25-6.25a.25.25 0 01-.073-.177zm-1.5 0V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 010 2.474l-5.026 5.026a1.75 1.75 0 01-2.474 0l-6.25-6.25A1.75 1.75 0 011 7.775zM6 5a1 1 0 100 2 1 1 0 000-2z">
                        </path>
                      </svg>
                      Immersive Video
                    </a>
                    
                    
                  </div>
                </div>
              </div>


              <div class="Box-body px-5 pb-5" style="z-index: 1">
                <article class="markdown-body entry-content container-lg"><h2 id="论文概况">论文概况</h2>
<p>Link：<a href="https://ieeexplore.ieee.org/document/9580281">QoE-driven Mobile 360 Video Streaming: Predictive
View Generation and Dynamic Tile Selection</a></p>
<p>Level：ICCC 2021</p>
<p>Keywords：QoE maximization，Trajectory-based viewport prediction，Dynamic tile selection，Differential weight on FOV tiles</p>
<h2 id="系统建模与形式化">系统建模与形式化</h2>
<h3 id="视频划分">视频划分</h3>
<p>先将视频划分成片段：$\Iota = {1, 2, &hellip;, I}$表示片段数为$I$的片段集合。</p>
<p>接着将片段在空间上均匀划分成$M \times N$个 tile，FOV 由被用户看到的 tile 所确定。</p>
<p>使用 ERP 投影，$(\phi_i, \theta_i),\ \phi_i \in (-180\degree, 180\degree], \theta_i \in (-90\degree, 90\degree]$来表示用户在第$i$个片段中的视点坐标。</p>
<p>播放过程中记录用户头部运动的轨迹，积累的数据可以用于 FOV 预测。</p>
<p>跨用户之间的 FOV 轨迹可以用于提高预测精度。</p>
<h3 id="qoe-模型">QoE 模型</h3>
<ul>
<li>
<p>前提</p>
<p>视频编解码器预先确定，无法调整每个 tile 的码率。</p>
</li>
<li>
<p>实现</p>
<ol>
<li>每个 tile 都以不同的码率编码成不同的版本。</li>
<li>每个 tile 都有两种分辨率的版本。</li>
</ol>
</li>
<li>
<p>QoE 内容</p>
<p>客户端收到的视频质量和观看时的卡顿时间。</p>
</li>
<li>
<p>质量形式化</p>
<p>对于每个片段$i \in \Iota$，$S_i = {\tau_{i, j}}_{j=1}^{M \times N}$是用来表示用户实际看到的 tile 的集合的向量。</p>
<p>$\tau_{i, j} = 1$表示第$i$个段中的第$j$个 tile 被看到；$\tau_{i, j} = 0$表示未被看到。</p>
<p>同样的， $\tilde{S}_i = {\tilde{\tau}_{i, j}}_{j = 1}^{M \times N}$ 表示经过 FOV 预测和 tile 选择之后成功被传送到用户头戴设备上的 tile 集合的向量。</p>
<p>$\tilde{\tau}_{i, j} = 1$表示第$i$个段中的第$j$个 tile 被用户接收；$\tilde{\tau}_{i, j} = 0$表示未被接收。</p>
<p>第$i$个段的可感知到的质量可以表示为：</p>
<p>$$
Q_i = \sum_{j = 1}^{M \times N} p_{i, j}b_{i, j}\tau_{i, j}\tilde{\tau}_{i, j}
$$</p>
<p>$b_{i, j}$表示第$i$个片段的第$j$个 tile 的码率；$p_{i, j}$表示对不同位置 tile 所分配的权重；</p>
</li>
<li>
<p>关于权重$p_{i, j}$</p>
<p>研究表明用户在全景视频 FOV 中的注意力分配并不是均等的，越靠近 FOV 中心的 tile 对用户的 QoE 贡献越大。</p>
<p>下面讨论单个片段的情况：用$(\phi_j, \theta_j)$表示 tile 中心点的坐标，并映射到笛卡尔坐标系上$(x_j, y_j, z_j)$：</p>
<p>$$
x_j = cos\theta_jcos\phi_j,\ y_j = sin\theta_j,\ z_j = -cos\theta_jsin\phi_j
$$</p>
<p>则两个 tile 之间的半径距离$d_{j, j&rsquo;}$可以表示为：</p>
<p>$$
d_{j, j&rsquo;} = arccos(x_j x_{j&rsquo;} + y_j y_{j&rsquo;} + z_j z_{j&rsquo;})
$$</p>
<p>对于第$i$个片段，假设用户 FOV 中心的 tile 为$j^*$，那么第$j$个 tile 的权重可以计算出来：</p>
<p>$$
p_{i, j} = (1 - d_{j, j^*} / \pi) \tau_{i, j}
$$</p>
</li>
<li>
<p>卡顿时间形式化</p>
<p>当$\tilde{\tau}_{i, j}$与$\tau_{i, j}$出现分歧时，用户就不能成功收到请求的 tile，头戴设备中显示的内容就会被冻结，由此导致卡顿。</p>
<p>对于任意的片段$i \in \Iota$，相应的卡顿时间$D_i$可以计算出来：</p>
<p>$$
D_i = \frac{\sum_{j = 1}^{M \times N} b_{i, j} \cdot [\tau_{i, j} - \tilde{\tau}_{i, j}]^+}{\xi}
$$</p>
<p>$[x]^+ = max \lbrace x, 0 \rbrace $；$\xi$表示可用的网络资源（已知，并且在推流过程中保持为常数）</p>
<p>卡顿发生于在播放时，用户 FOV 内的 tile 还没有被传输到用户头戴设备中的时刻，终止于所有 FOV 内 tile 被成功传送的时刻。</p>
</li>
<li>
<p>质量与卡顿时间的结合</p>
<p>$$
max\ QoE = \sum_{i = 1}^I (Q_i - wD_i)
$$</p>
<p>$w$表示卡顿事件的惩罚权重。例如，w＝1000 意味着 1 秒视频暂停接收的 QoE 惩罚与将片段的比特率降低 1000 bps 相同。</p>
</li>
</ul>
<h2 id="联合-viewport-预测与-tile-选择">联合 viewport 预测与 tile 选择</h2>
<p>联合框架包括 viewport 预测和动态 tile 选择两个阶段。</p>
<p>viewport 预测阶段集成带有注意力机制的 RNN，接收用户的历史头部移动信息作为输入，输出每个 tile 出现在 FOV 中的可能性分布。</p>
<p>选择 tile 阶段为预测的输出建立的上下文空间，基于上下文赌博机学习算法来选择 tile 并确定所选 tile 的质量版本。</p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211219115244821.png" alt="Framework"></p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211219114234338.png" alt="overall algorithm"></p>
<h3 id="viewport-预测">Viewport 预测</h3>
<p>FOV 预测问题可以看作是序列预测问题。</p>
<p>不同用户观看相同视频时的头部移动轨迹有强相关性，所以跨用户的行为分析可以用于提高新用户的 viewport 预测精度。</p>
<p>被广泛使用的 LSTM 的变体——Bi-LSTM（Bi-directional LSTM）用于 FOV 预测。</p>
<ol>
<li>
<p>输入参数构造</p>
<p>为了构造 Bi-LSTM 学习网络，需要对不同用户的 viewpoint 特性作表征。</p>
<ul>
<li>
<p>在用户观看事先划分好的$I$个片段时，记录每个片段对应的 viewpoint 坐标：</p>
<p>$\Phi_{1:I} = {\phi_i}^I_{i = 1},\ \Theta_{1:I} = {\theta_i}^I_{i=1}$</p>
</li>
<li>
<p>预测时使用的历史信息的窗口大小记为$k$；</p>
</li>
<li>
<p>对于第$i, (i &gt; k)$个片段，相应的 viewpoint 特性由$\Phi_{i-1:i-k}$和$\Theta_{i-1:i-k}$所给出；</p>
</li>
<li>
<p>列索引$m_i$和行索引$n_i$作为 viewpoint tile $(\phi_i, \theta_i)$的标签，由<a href="https://zh.wikipedia.org/wiki/One-hot">独热编码</a>表示；</p>
</li>
<li>
<p>通过滑动预测的窗口，所看到的视频片段的特性和标签可以被获取。</p>
</li>
</ul>
</li>
<li>
<p>LSTM 网络构造</p>
<p>整个网络包含 3 层：</p>
<ul>
<li>遗忘门层决定丢弃哪些信息；</li>
<li>更新门层决定哪类信息需要存储；</li>
<li>输出门层过滤输出信息。</li>
</ul>
<p>为了预测用户在第$i$个段的 viewpoint，LSTM 网络接受$\Phi_{i-1:i-k}$和$\Theta_{i-1:i-k}$作为输入；输出行列索引；</p>
<p>$$
m_i = LSTM(\theta_{i-k}, &hellip;, \phi_{i-1}; \alpha)
$$</p>
<p>$$
n_i = LSTM(\theta_{i-k}, &hellip;, \theta_{i-1}; \beta)
$$</p>
<p>$\alpha, \beta$是学习网络的参数；分类交叉熵被用作网络训练的损失函数。</p>
</li>
<li>
<p>Bi-LSTM 的特殊构造</p>
<ul>
<li>
<p>将公共单向的 LSTM 划分成 2 个方向。</p>
<p>当前片段的输出利用前向和反向信息，这为网络提供了额外的上下文，加速了学习过程。</p>
</li>
<li>
<p>双向的 LSTM 不直接连接，不共享参数。</p>
</li>
<li>
<p>每个时间槽的输入会被分别传输到前向和反向的 LSTM 中，并分别根据其状态产生输出。</p>
</li>
<li>
<p>两个输出直接连接到 Bi-LSTM 的输出节点。</p>
</li>
<li>
<p>引入注意力机制为每步时间自动分配权重，从大量信息中选择性地筛选出重要信息。</p>
</li>
<li>
<p>将 Softmax 层堆叠在网络顶部，以获取不同 tile 的 viewpoint 概率。</p>
</li>
</ul>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211217180521259.png" alt="image-20211217180521259"></p>
<h3 id="动态-tile-选择">动态 tile 选择</h3>
<p>使用上下文赌博机学习算法来补偿 viewport 预测错误对 QoE 造成的影响。</p>
<ul>
<li>
<p>上下文赌博机学习算法概况</p>
<p>上下文赌博机学习算法是一个基于特征的 exploration-exploitation 技术。</p>
<p>通过在多条手臂上重复执行选择过程，可以获得在不同上下文中的每条手臂的回报。</p>
<p>通过 exploration-exploitation，目标是最大化累积的回报。</p>
</li>
<li>
<p>组成部分形式化</p>
<ol>
<li>
<p>上下文</p>
<p>直觉上讲，当预测的 viewpoint 不够精确时，需要扩大 FOV 并选择更多的 tile 进行传输。</p>
<p>为了做出第$i$个片段上的预测 viewpoint 填充决策，定义串联的上下文向量：</p>
<p>$c_i = [f^s_i, f^c_i]$，$f^s_i$表示自预测的上下文，$f^c_i$表示跨用户之间的预测上下文。</p>
<p>预测输出的用户$u$的 viewpoint tile 索引用$[\tilde{m}^u_{i-1}, \tilde{n}^u_{i-1}]$表示；</p>
<p>实际的用户$u$的 viewpoint tile 索引用$[m_{i-1}^u, n_{i-1}^u]$表示；</p>
<p>那么对第$i$个片段而言，自预测的上下文可以计算出来：</p>
<p>$$
f_i^s = [|m_{i-1}^u - \tilde{m}^u_{i-1}|, |n_{i-1}^u - \tilde{n}^u_{i-1}|]
$$</p>
<p>跨用户的上下文信息获取：使用 KNN 准则选择一组用户，其在前$k$个片段中的轨迹最接近用户$u$的轨迹。</p>
<p>使用$\zeta$表示获得的用户集合，使用</p>
<p>$$E_{\zeta_u}(m_i) = \frac{1}{|\zeta_u|}\sum_{u \in \zeta_u} |m_i^u - \tilde{m}_i^u|$$</p>
<p>$$E_{\zeta_u}(n_i) = \frac{1}{|\zeta_u|}\sum_{u \in \zeta_u}|n_i^u - \tilde{n}_i^u|$$</p>
<p>表示预测误差，则：</p>
<p>$$
f_i^u = [E_{\zeta_u}(m_i), E_{\zeta_u}(n_i)]
$$</p>
</li>
<li>
<p>手臂</p>
<p>根据从第一个阶段得到的每个 tile 的可能性分布，所有的 tile 可以用倒序的方式排列。</p>
<p>最高可能性的 tile 被看作 FOV 的中心，高码率以此 tile 为中心分配。</p>
<p>剩余的带宽用于扩展 FOV，低可能性的 tile 被顺序选择来扩展 FOV 直至带宽耗尽。</p>
<p>手臂的状态$a \in {0, 1}$表示 tile 选择的策略：</p>
<ul>
<li>$a = 0$表示 viewpoint 预测准确，填充 tile 分配了高质量；</li>
<li>$a = 1$表示 viewpoint 预测不准确，填充 tile 分配的质量较低，为了传送尽可能多的 tile 而减少卡顿；</li>
</ul>
</li>
<li>
<p>回报</p>
<p>给定上下文$c_i$，选择手臂$a$，预期的回报$r_{i, a}$建模为$c_i$和$a$组合的线性函数：</p>
<p>$$
\Epsilon[r_{i, a}|c_{i, a}] = c_{i, a}^T \theta_a^*
$$</p>
<p>未知参数$\theta_a$表示每个手臂的特性，目标是为第$i$个片段选择最优的手臂：</p>
<p>$$
a_i^* = \underset{a}{argmax}\ c_{i, a}^T \theta_a^*
$$</p>
<p>使用<a href="https://zhuanlan.zhihu.com/p/38875273">LinUCB</a>算法做出特征向量的精确估计并获取$\theta_a^*$。</p>
<p><img src="https://raw.githubusercontent.com/ayamir/blog-imgs/main/image-20211219115320503.png" alt="tile selection"></p>
</li>
</ol>
</li>
</ul>
<h2 id="实验评估">实验评估</h2>
<ul>
<li>
<p>评估准备</p>
<ul>
<li>使用现有的<a href="https://github.com/xuyanyu-shh/VR-EyeTracking">viewpoint 轨迹数据集</a>，所有视频被编码为至少每秒 25 帧，长度为 20 到 60 秒；</li>
<li>视频每个片段被划分为$6 \times 12$的 tile，每个的角度是$30\degree \times 30\degree$；</li>
<li>初始 FOV 设定为$90\degree \times 90\degree$，在 viewpoint 周围是$3 \times 3$的 tile；</li>
<li>每个片段的长度为 500ms；</li>
<li>默认的预测滑动窗口大小$k = 5$；</li>
<li>HD 和 LD 版本分别以按照 HEVC 的$QP={32, 22}$的参数编码而得到；</li>
<li>训练集和测试集的比例为$7:3$；</li>
<li>Bi-LSTM 层配置有 128 个隐单元；</li>
<li>batch 大小为 64；</li>
<li>epoch 次数为 60；</li>
</ul>
</li>
<li>
<p>性能参数</p>
<ul>
<li>
<p>预测精度</p>
</li>
<li>
<p>视频质量</p>
<p>由传送给用户的有效码率决定：例如实际 FOV 中的 tile 码率总和</p>
</li>
<li>
<p>卡顿时间</p>
</li>
<li>
<p>规范化的 QoE</p>
<p>实际取得的 QoE 与在 viewpoint 轨迹已知情况下的 QoE 的比值</p>
</li>
</ul>
</li>
<li>
<p>对比目标</p>
<ul>
<li>预测阶段——预测精度
<ol>
<li>LSTM</li>
<li>LR</li>
<li>KNN</li>
</ol>
</li>
<li>取 tile 的阶段——规范化的 QoE
<ol>
<li>两个阶段都使用纯 LR</li>
<li>只预测而不做动态选择</li>
</ol>
</li>
</ul>
</li>
</ul></article>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </main>
</div>
<script type="application/javascript" src='https://ayamir.github.io/js/toc.js'></script>
<link rel="stylesheet" href='https://ayamir.github.io/css/toc.css' />


<div id="gitalk-container" class="gitalk-container"></div>
<link rel="stylesheet" href='https://ayamir.github.io/css/gitalk.css'>
<script src='https://ayamir.github.io/js/gitalk.min.js'></script>
<script>
  const gitalk = new Gitalk({
    clientID: '1ee3454a8f1f370a7934',
    clientSecret: '737cbeaf81ce60b50fafd2b0d6c7ebfa42826555',
    repo: 'ayamir.github.io',
    owner: 'ayamir',
    admin: ['ayamir'],
    id: eval("location.pathname"), 
    distractionFreeMode: false 
  });
  (function() {
    gitalk.render('gitalk-container');
  })();
</script>


  <div class="footer container-xl width-full p-responsive">
  <div
    class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between flex-sm-items-center pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light ">
    <a aria-label="Homepage" title="GitHub" class="footer-octicon d-none d-lg-block mr-lg-4" href="https://ayamir.github.io/">
      <svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="24">
        <path fill-rule="evenodd"
          d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z">
        </path>
      </svg>
    </a>
    <ul class="list-style-none d-flex flex-wrap col-12 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0">
      
      <li class="mr-3 mr-lg-0">Theme by <a href='https://github.com/MeiK2333/github-style'>github-style</a></li>
      
    </ul>
  </div>
  <div class="d-flex flex-justify-center pb-6">
    <span class="f6 text-gray-light"></span>
  </div>


</div>
</body>

<script type="application/javascript" src="https://ayamir.github.io/js/github-style.js"></script>

<link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>




</html>